{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70548cdc-288f-4509-aa2b-0d91629080c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snscrape\n",
      "  Downloading snscrape-0.5.0.20230113-py3-none-any.whl (69 kB)\n",
      "     --------------------------------------- 69.2/69.2 kB 68.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests[socks] in c:\\anaconda4\\lib\\site-packages (from snscrape) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\anaconda4\\lib\\site-packages (from snscrape) (3.6.0)\n",
      "Requirement already satisfied: lxml in c:\\anaconda4\\lib\\site-packages (from snscrape) (4.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\anaconda4\\lib\\site-packages (from snscrape) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\anaconda4\\lib\\site-packages (from beautifulsoup4->snscrape) (2.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\anaconda4\\lib\\site-packages (from requests[socks]->snscrape) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda4\\lib\\site-packages (from requests[socks]->snscrape) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda4\\lib\\site-packages (from requests[socks]->snscrape) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda4\\lib\\site-packages (from requests[socks]->snscrape) (3.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\anaconda4\\lib\\site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Installing collected packages: snscrape\n",
      "Successfully installed snscrape-0.5.0.20230113\n"
     ]
    }
   ],
   "source": [
    "!pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc8bf03-45a9-4de0-b2a7-06a2579c1f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm #gives us a progress bar\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed28bb9e-1908-4052-958f-f8790904b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = sntwitter.TwitterSearchScraper(\"#python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60fd70a8-9a8b-424b-9574-bab23a358e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in scraper.get_items():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410b091d-1ff7-4387-b0fc-39a7399e36a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet(url='https://twitter.com/DrMattCrowson/status/1629017825238220800', date=datetime.datetime(2023, 2, 24, 7, 18, 9, tzinfo=datetime.timezone.utc), rawContent='RT Neural Network from scratch (no numpy) Part I https://t.co/S3lNNDFJkf #neuralnetworkalgorithm #deeplearning #python #machinelearning https://t.co/PzCJg3mt3j', renderedContent='RT Neural Network from scratch (no numpy) Part I dlvr.it/SjwCxh #neuralnetworkalgorithm #deeplearning #python #machinelearning https://t.co/PzCJg3mt3j', id=1629017825238220800, user=User(username='DrMattCrowson', id=18622427, displayname='Reluctant Quant', rawDescription='Hearing & Balance Surgeon @MassEyeAndEar Asst Professor @HarvardMed | #DataScience #MachineLearning | Washed up #HockeyGoalie', renderedDescription='Hearing & Balance Surgeon @MassEyeAndEar Asst Professor @HarvardMed | #DataScience #MachineLearning | Washed up #HockeyGoalie', descriptionLinks=None, verified=False, created=datetime.datetime(2009, 1, 5, 3, 43, 21, tzinfo=datetime.timezone.utc), followersCount=1114, friendsCount=2080, statusesCount=44901, favouritesCount=2711, listedCount=54, mediaCount=41054, location='BOS/YOW', protected=False, link=None, profileImageUrl='https://pbs.twimg.com/profile_images/924360671814438912/9rTkqVrY_normal.jpg', profileBannerUrl='https://pbs.twimg.com/profile_banners/18622427/1506018188', label=None), replyCount=0, retweetCount=0, likeCount=0, quoteCount=0, conversationId=1629017825238220800, lang='en', source='<a href=\"https://dlvrit.com/\" rel=\"nofollow\">dlvr.it</a>', sourceUrl='https://dlvrit.com/', sourceLabel='dlvr.it', links=[TextLink(text='dlvr.it/SjwCxh', url='http://dlvr.it/SjwCxh', tcourl='https://t.co/S3lNNDFJkf', indices=(49, 72))], media=[Photo(previewUrl='https://pbs.twimg.com/media/FptvFDvaAAEFnbz?format=png&name=small', fullUrl='https://pbs.twimg.com/media/FptvFDvaAAEFnbz?format=png&name=large', altText=None)], retweetedTweet=None, quotedTweet=None, inReplyToTweetId=None, inReplyToUser=None, mentionedUsers=None, coordinates=None, place=None, hashtags=['neuralnetworkalgorithm', 'deeplearning', 'python', 'machinelearning'], cashtags=None, card=None, viewCount=None, vibe=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e6a62e1-d91d-4a59-8c62-cade10297185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snscrape.modules.twitter.Tweet"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6c0801-2211-4182-a6af-b18ef890d726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026b07531d46413ebc56801fe01e3088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#extracting tweet data\n",
    "scraper = sntwitter.TwitterSearchScraper(\"#python\")\n",
    "tweets = []\n",
    "n_tweets = 1_000\n",
    "for i, tweet in tqdm(enumerate (scraper.get_items()), total = n_tweets):\n",
    "    data = [tweet.date,\n",
    "            tweet.id,\n",
    "            tweet.rawContent,\n",
    "            tweet.user.username,\n",
    "            tweet.likeCount,\n",
    "            tweet.retweetCount]\n",
    "    tweets.append(data)\n",
    "    if i > n_tweets:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1560f39-2b7f-416f-97d4-a759fb2587ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame(tweets, columns = ['date','id','content','username','like count','reTweetCount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ce3355e-a4c7-4419-8c02-603acf18f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.to_csv('python-tweets',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
